<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Open-Source AI Models: DeepSeek and Qwen</title>
    <link rel="stylesheet" href="../master.css">
</head>
<body>
    <div>
        <p><a href="../index.html">Return to Main Page</a></p>

        <h1>Open-Source AI Models: DeepSeek and Qwen</h1>

        <p>
            As a computer science graduate, I’ve been exploring open-source artificial intelligence models to understand how they work and what they can do. I’ve been running two models on my system, DeepSeek and Qwen, and they’ve been fascinating to work with. This page shares why I chose open-source AI, my experiences with these models, honest thoughts on their strengths and challenges, and what I’ve learned along the way.
        </p>

        <h2>Why Open-Source AI?</h2>

        <p>
            Open-source AI models are a brilliant choice for someone like me, fresh out of university and eager to experiment without breaking the bank. Unlike paid models from big companies, open-source options like DeepSeek and Qwen are free to use, which is perfect for tinkering on personal projects. They also come with source code, so I can dig into how they’re built, tweak them for my needs, or even contribute to their development. The community around these models is vibrant, with developers sharing tips and updates, which makes learning faster and more exciting. As a computer science graduate, I value the flexibility to run these models locally on my own hardware, giving me control over data privacy and the chance to optimise performance for my setup.
        </p>

        <h2>Running DeepSeek on My System</h2>

        <p>
            DeepSeek, developed by a Chinese company, has been a standout model for me, particularly its R1 version, which is designed for reasoning tasks. I’ve been running it on my laptop, which has a decent GPU and 16GB of RAM, though it’s not top-of-the-line. Setting it up was straightforward, requiring Python and a few libraries, and the open-source MIT licence made it easy to download and use. I’ve used DeepSeek R1 for coding assistance, like debugging Python scripts, and for research tasks, such as summarising technical papers. It’s impressively fast and often matches the performance of premium models like OpenAI’s o1, which is surprising for an open-source tool. For example, it can solve complex logic problems or explain algorithms clearly, which has been handy for revising computer science concepts. Its efficiency is a big plus, as it uses fewer computational resources than some competitors, making it viable on my modest system. However, it needs a fair bit of memory for larger tasks, and I’ve had to tweak settings to avoid slowdowns, which was a bit of a learning curve.
        </p>

        <h2>Running Qwen on My System</h2>

        <p>
            Qwen, created by Alibaba, is another model I’ve been experimenting with, specifically the Qwen 2.5 version. Like DeepSeek, it’s open-source and runs on my laptop after installing the necessary dependencies. Qwen 2.5 is versatile, excelling in tasks like generating text, answering questions, and even handling some coding queries. I’ve used it for writing project documentation and exploring natural language processing ideas, such as building a simple chatbot. It’s particularly good at producing complete and accurate responses, often outperforming DeepSeek in content-heavy tasks, like explaining machine learning concepts in detail. Setting up Qwen was slightly trickier than DeepSeek, as it required careful configuration to run smoothly on my hardware, but the community documentation helped. Its performance is close to top models like GPT-4o, which is exciting for an open-source option, though it can be slower for reasoning tasks compared to DeepSeek R1. I’ve found Qwen’s ability to handle diverse queries makes it a great all-rounder for my experiments.
        </p>

        <h2>Honest Thoughts</h2>

        <p>
            Both DeepSeek and Qwen are remarkable for open-source models, and I’m genuinely impressed by how close they come to paid alternatives. DeepSeek R1’s reasoning skills are a highlight, making it my go-to for technical tasks like coding or problem-solving. Its efficiency means I can run it without needing a super-powerful computer, which is ideal for a graduate like me. Qwen 2.5, on the other hand, shines in generating detailed and coherent text, which has been useful for writing and learning. The fact that both are free and open-source is a game-changer, letting me experiment without worrying about subscription costs or data privacy issues that come with cloud-based models. The community support for both models is fantastic, with forums and guides helping me troubleshoot issues like memory errors or setup hiccups.
        </p>

        <p>
            That said, there are challenges. Both models demand a fair amount of hardware power, especially for larger tasks, and my laptop sometimes struggles, requiring me to optimise settings or limit input sizes. As a computer science graduate, I enjoy the challenge of tweaking configurations, but it might be daunting for less technical users. Another issue is that some companies hesitate to adopt DeepSeek and Qwen because they’re developed in China, which can raise concerns about data security or compliance in enterprise settings. This hasn’t affected me personally, as I’m using them for personal projects, but it’s something to consider for professional use. False positives aren’t a big issue, as both models are reliable when properly configured, but getting them to that point takes some effort. Despite these hurdles, the benefits far outweigh the drawbacks, and I’ve learned a ton from working through them.
        </p>

        <h2>Lessons Learned</h2>

        <p>
            Running DeepSeek and Qwen has taught me a lot about AI and system management. Technically, I’ve improved my skills in setting up Python environments, managing GPU resources, and optimising model performance, which are valuable for any computer science career. I’ve also learned to critically evaluate AI models, comparing their strengths, like DeepSeek’s reasoning versus Qwen’s text generation, and understanding their limits, such as hardware demands. Practically, I’ve seen the power of open-source communities, where developers share solutions and ideas freely, making complex technology accessible. As a graduate, I’ve realised that open-source AI is not just about free tools—it’s about innovation and control, letting me shape technology to fit my goals. These lessons have deepened my interest in AI and prepared me for real-world challenges, like deploying models in resource-constrained environments.
        </p>

        <h2>Future Aspirations</h2>

        <p>
            Working with DeepSeek and Qwen has sparked my ambition to dive deeper into AI development. I hope to build my own AI tools, perhaps a coding assistant or a research summariser, using these models as a foundation. Contributing to their open-source projects would be exciting, maybe by improving documentation or adding features for easier setup. I also want to explore how these models can solve real-world problems, like automating data analysis or enhancing cybersecurity, which aligns with my computer science background. Professionally, I aim to use this experience to land a role in AI or cloud computing, where I can apply my skills to innovative projects. The open-source AI boom, led by models like DeepSeek and Qwen, feels like the start of something big, and I’m keen to be part of it.
        </p>

        <h2>Conclusion</h2>

        <p>
            Exploring open-source AI with DeepSeek and Qwen has been an eye-opening journey for me as a computer science graduate. These models offer incredible performance, from DeepSeek’s sharp reasoning to Qwen’s versatile text generation, all without the cost of proprietary systems. Running them on my system has shown me the potential of open-source technology, as well as the challenges of hardware limits and configuration. Honestly, the experience has been rewarding, teaching me technical skills and the value of community-driven innovation. I’m excited to keep experimenting, contributing, and building on these models to shape my future in AI. For anyone starting out in computer science, I’d recommend diving into open-source AI—it’s a brilliant way to learn, create, and make a difference.
        </p>
    </div>
</body>
</html>
